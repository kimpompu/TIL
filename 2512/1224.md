# 251224 TIL

Q: 알림 서비스에서 Kafka를 사용한 이유는 무엇이며, 어떤 장점을 얻었나요?

A: 서비스 간의 결합도를 낮추고 비동기 통신을 통해 성능을 최적화하기 위해 Kafka를 도입했습니다. 댓글 작성과 같은 이벤트 발생 시, 알림 서비스가 직접 호출되는 대신 Kafka 토픽에 이벤트를 발행하면 알림 서비스가 이를 구독하여 처리합니다. 이를 통해 댓글 서비스의 응답 지연을 방지하고, 알림 시스템에 장애가 발생해도 댓글 서비스에 영향을 주지 않는 안정성을 확보했습니다. 또한, 트래픽이 폭주할 경우 메시지 큐에 버퍼링하여 시스템 과부하를 막을 수 있습니다.

Q: 실시간 알림 전송을 위해 SSE(Server-Sent Events)를 선택한 이유는 무엇인가요? WebSocket과 비교했을 때의 장단점은?

A: 알림은 서버에서 클라이언트로 데이터를 보내는 단방향 통신이 주를 이루기 때문에 SSE가 적합하다고 판단했습니다. WebSocket은 양방향 통신을 지원하지만 프로토콜이 무겁고 구현이 복잡할 수 있습니다. 반면 SSE는 HTTP 기반으로 가볍고 구현이 간단하며, 자동 재연결 기능을 지원합니다. 채팅과 같이 양방향 통신이 필요한 기능은 WebSocket을 사용하고, 알림과 같이 단방향 푸시가 필요한 기능은 SSE를 사용하여 각 기술의 장점을 살렸습니다.

Q: 알림 데이터를 MongoDB에 저장한 이유는 무엇인가요? RDBMS와 비교했을 때의 장점은?

A: 알림 데이터는 비정형적이고 스키마가 자주 변경될 수 있으며, 대량의 쓰기 작업이 발생할 수 있습니다. MongoDB는 스키마가 유연하여 다양한 형태의 알림 데이터를 저장하기 용이하고, 쓰기 성능이 우수하여 대량의 알림 트래픽을 효율적으로 처리할 수 있습니다. 또한, 오래된 알림 데이터를 자동으로 삭제하는 TTL(Time-To-Live) 인덱스 기능을 활용하여 데이터 관리 비용을 절감할 수 있다는 장점도 고려했습니다.

Q: 다중 서버 환경에서 SSE 연결을 관리할 때 발생할 수 있는 문제는 무엇이며, 어떻게 해결했나요? (Redis Pub/Sub 활용)

A: 다중 서버 환경에서는 클라이언트가 특정 서버에만 SSE 연결을 맺고 있기 때문에, 알림을 발생시키는 이벤트가 다른 서버에서 처리될 경우 해당 클라이언트에게 알림을 전송할 수 없는 문제가 발생합니다. 이를 해결하기 위해 Redis Pub/Sub을 도입했습니다. 알림 이벤트가 발생하면 Redis 채널에 메시지를 발행하고, 모든 알림 서비스 인스턴스가 이를 구독하여 자신의 서버에 연결된 클라이언트에게 알림을 전송하도록 구현했습니다.

Q: 알림 전송 실패 시 재시도 전략은 어떻게 구현했나요? (Kafka DLQ 활용)

A: Kafka Consumer에서 알림 처리 중 예외가 발생할 경우, 즉시 실패 처리하지 않고 일정 횟수만큼 재시도를 수행합니다. 재시도 후에도 실패한 메시지는 Dead Letter Queue(DLQ)로 보내 별도로 저장하고, 추후 개발자가 원인을 분석하거나 수동으로 재처리할 수 있도록 구현하여 알림 유실을 방지했습니다.

Q: SseEmitter 사용 시 발생할 수 있는 메모리 누수나 타임아웃 문제는 어떻게 해결했나요?

A: SseEmitter 생성 시 타임아웃 시간을 설정하고, onCompletion 및 onTimeout 콜백 메서드를 통해 연결이 종료되거나 타임아웃될 때 해당 Emitter를 저장소(Repository)에서 안전하게 제거하도록 구현했습니다. 또한, 더미 데이터를 주기적으로 전송하여 연결이 끊어지지 않도록 관리했습니다.

Q: 알림 서비스의 성능을 모니터링하기 위해 어떤 지표를 확인하시나요?

A: Kafka Consumer Lag(처리 지연), 알림 전송 성공/실패 횟수, SSE 연결 수 등을 주요 지표로 모니터링합니다. Prometheus와 Grafana를 활용하여 시각화하고, 특정 임계치를 초과할 경우 알림을 받도록 설정하여 장애에 신속하게 대응할 수 있도록 했습니다.

Q: 댓글 서비스에서 PostgreSQL을 선택한 이유는 무엇인가요?

A: 댓글 데이터는 게시글, 사용자 등 다른 엔티티와의 관계가 명확하고 데이터의 무결성이 중요하기 때문에 RDBMS인 PostgreSQL을 선택했습니다. 트랜잭션 관리가 용이하고 복잡한 조인 쿼리를 효율적으로 처리할 수 있어 댓글 목록 조회 및 계층형 댓글 구현에 적합하다고 판단했습니다.

Q: 대댓글(답글) 기능을 구현할 때 DB 스키마는 어떻게 설계했나요?

A: 댓글 테이블에 parent_id 컬럼을 추가하여 자기 참조(Self-Referencing) 관계를 맺도록 설계했습니다. 최상위 댓글은 parent_id가 NULL이고, 대댓글은 부모 댓글의 ID를 가집니다. 이를 통해 무한 계층 구조를 표현할 수 있으며, 조회 시에는 재귀 쿼리(Recursive Query)나 애플리케이션 로직을 통해 계층 구조를 구성하여 반환합니다.

Q: 댓글 목록 조회 성능을 최적화하기 위해 어떤 방법을 사용했나요? (인덱싱, 캐싱 등)

A: 댓글 목록 조회는 빈번하게 발생하는 작업이므로 feed_id와 created_at 컬럼에 복합 인덱스를 생성하여 조회 성능을 개선했습니다. 또한, 자주 조회되는 인기 게시글의 댓글 목록은 Redis에 캐싱하여 DB 부하를 줄이고 응답 속도를 높였습니다.

Q: 다른 서비스(User, Feed)의 데이터를 조회할 때 Feign Client를 사용했는데, 발생할 수 있는 문제는 무엇이며 어떻게 해결했나요?

A: Feign Client는 동기 방식이므로 타 서비스 장애나 지연이 댓글 서비스에 직접적인 영향을 줄 수 있습니다. 이를 방지하기 위해 Resilience4j의 Circuit Breaker를 적용하여 타 서비스에 문제가 생겼을 때 빠르게 실패 처리하거나 대체 로직(Fallback)을 실행하도록 구현했습니다. 또한, 인증 헤더 전파를 위해 RequestInterceptor를 사용하여 JWT 토큰 등을 자동으로 전달하도록 설정했습니다.

Q: 댓글 작성 시 동시성 이슈(예: 좋아요 수 집계)는 어떻게 처리했나요?

A: 좋아요 수와 같은 집계 데이터는 동시 수정이 빈번하게 발생할 수 있습니다. 이를 해결하기 위해 DB의 비관적 락(Pessimistic Lock)이나 낙관적 락(Optimistic Lock)을 사용할 수 있지만, 성능 저하를 우려하여 Redis의 INCR 명령어를 사용하여 원자적(Atomic)으로 카운트를 증가시키는 방식을 채택했습니다. DB에는 일정 주기마다 동기화하거나 이벤트를 통해 비동기로 업데이트하는 방식을 고려했습니다.

Q: 댓글 서비스의 트랜잭션 관리 전략은 무엇인가요? (예: 댓글 저장 후 알림 발송 실패 시)

A: 댓글 저장과 알림 발송은 분산 트랜잭션 문제입니다. 2PC(Two-Phase Commit)는 성능 저하가 심하므로, Saga 패턴이나 이벤트 기반의 최종 일관성(Eventual Consistency) 모델을 적용했습니다. 댓글이 저장되면 Kafka 이벤트를 발행하고 트랜잭션을 커밋합니다. 알림 발송이 실패하더라도 댓글 저장은 유지되며, 알림 서비스에서 재시도 로직을 통해 성공을 보장하거나 실패 로그를 남기는 방식으로 처리하여 댓글 서비스의 가용성을 우선시했습니다.

Q: MSA 환경에서 댓글 서비스의 배포 및 확장 전략은?

A: Docker 컨테이너로 패키징하여 배포하며, 트래픽 증가 시 Kubernetes의 HPA(Horizontal Pod Autoscaler) 등을 통해 댓글 서비스 인스턴스만 독립적으로 스케일 아웃할 수 있도록 구성했습니다. DB 부하 분산을 위해 읽기 전용 복제본(Read Replica)을 도입하는 것도 고려할 수 있습니다.

Q: 댓글 수정/삭제 시 권한 체크는 어떻게 구현했나요?

A: 요청을 보낸 사용자의 ID(JWT에서 추출)와 댓글 작성자의 ID를 비교하여 일치하는 경우에만 수정/삭제를 허용했습니다. 관리자 권한을 가진 사용자는 작성자와 무관하게 삭제할 수 있도록 별도의 권한 로직을 추가했습니다. 이러한 권한 체크 로직은 서비스 계층이나 AOP를 활용하여 비즈니스 로직과 분리하여 관리했습니다.